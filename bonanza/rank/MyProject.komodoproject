import sys
import re
import idf_gen
import heapq
from math import log

class RankingBuilder(object):
    def __init__(self):
        self.query = None
        self.url = None
        self.key = None
        self.anchor_text = None
    def add_url(self, query, url):
        self.queries[self.query].append(url)
        self.features[self.query][url] = {}
        self.url = value
    def add_query(self, query):
        self.query = value
        self.queries[self.query] = []
        self.features[self.query] = {}
    def add_title(self, title):
        self.features[self.query][self.url][self.key] = title
    def add_header(self, header):
        curHeader = self.features[self.query][self.url].setdefault(self.key, [])
        curHeader.append(header)
        self.features[self.query][self.url][self.key] = curHeader
    def add_body_hits(self, body_hits):
        if key not in self.features[self.query][self.url]:
          self.features[self.query][self.url][self.key] = {}
        temp = body_hits.split(' ', 1)
        self.features[self.query][self.url][self.key][temp[0].strip()] \
                    = [int(i) for i in temp[1].strip().split()]
    def add_body_length(self, body_length):
        self.features[self.query][self.url][self.key] = int(body_length)
    def add_anchor_text(self, query, url, anchor_text):
        self.anchor_text = anchor_text
        if 'anchors' not in self.features[self.query][self.url]:
            self.features[self.query][self.url]['anchors'] = {}            
    def add_anchor_count(self, anchor_count):
        self.features[self.query][self.url]['anchors'][self.anchor_text] = int(anchor_count)
    def extractFeatures(self, featureFile):
        f = open(featureFile, 'r')
        self.queries = {}
        self.features = {}
        for line in f:
          self.key = line.split(':', 1)[0].strip()
          value = line.split(':', 1)[-1].strip()
          if(key == 'query'):
            self.add_query(value)
          elif(key == 'url'):
            self.add_url(value) 
          elif(key == 'title'):
            self.add_title(value)
          elif(key == 'header'):
            self.add_header(value)
          elif(key == 'body_hits'):
            self.add_body_hits(value)
          elif(key == 'body_length'):
            self.add_body_length(value)
          elif (key == 'pagerank'):
            self.add_body_length(value)
          elif(key == 'anchor_text'):
            self.add_anchor_text(query, url, value)
          elif(key == 'stanford_anchor_count'):
            self.add_anchor_count(value)
          
        f.close()
        return (self.queries, self.features) 
        
        
class CSRankingBuilder(RankingBuilder):
    def __init__(self, params):
        super(CSRankingBuilder, self).__init__()
        self.params = params
    def add_terms(self, term_list, vector):
        for term in terms:
            vector.add_term(term)
    def add_sentence(self, sentence, vector):
        self.add_terms(sentence.split(), vector)                
    def add_query(self, query):
        self.query = query
        self.queries[query] = QueryModel(self.params, query)
    def add_url(self, url):
        self.url = UrlModel(self.query, self.params)
        current = self.queries[self.query]
        current.add_url(self.url)
        self.add_terms(re.sub(r'\W', ' ', url).split(), self.url.url_vec)
    def add_title(self, title):
        self.add_sentence(title, self.url.title_vec)
    def add_header(self, header):
        self.add_sentence(title, self.url.header_vec)
    def add_body_hits(self, body_hits):
        temp = body_hits.split(' ', 1)
        term = temp[0].strip()
        postings = temp[1].strip().split()
        for posting in postings: 
            self.add_sentence(term, self.url.body_hits_vec)
    def add_body_length(self, body_length):
        self.url.body_length = int(body_length)
    def add_anchor_text(self, query, url, anchor_text):
        self.anchor_text = anchor_text
    def add_anchor_count(self, anchor_count):
        for anchor in self.anchor_text.split():
            for i in range(anchor_count):
                self.add_sentence(anchor, self.url.anchor_vec)
                
                
class QueryModel(object):
    def __init__(self, q, p):
        self.query = q
        self.params = p
        self.query_vec = QueryVector(p.tf_computer)
        self.urls = []
    def add_url(self, url):
        self.urls.append(url)
    def compute_scores(self):
        scores = []
        for url in self.urls:
            heapq.heappush(scores, (-1*url.compute_score(self.query_vec), url))
        return (q, scores)
            
            
class UrlModel(object):
    def __init__(self, p, q):
        self.url_vec = CSDocumentVector(p, q)
        self.title_vec = CSDocumentVector(p, q)
        self.headers_vec = CSDocumentVector(p, q)
        self.body_hits_vec = CSDocumentVector(p, q)
        self.anchors_vec = CSDocumentVector(p, q)
    def compute_score(self, query_vec):
        u = [self.params.up * e for e in self.url_vec.value(self.body_length)]
        t = [self.params.tp * e for e in self.title_vec.value(self.body_length)]
        h = [self.params.hp * e for e in self.headers_vec.value(self.body_length)]
        bh = [self.params.bp * e for e in self.body_hits_vec.value(self.body_length)]
        ah = [self.params.ap * e for e in self.anchors_vec.value(self.body_length)]
        lu = len(u)
        assert lu == len(t) and len(h) == lu and len(bh) == lu and len(ah) == lu
        doc_score = [u[i]+t[i]+h[i]+bh[i]+au[i] for i in range(len(u))]
        return self.dot(doc_score, query_vec.value())
    def dot(self, v, v1):
        assert len(v) == len(v1)
        sum = 0
        for i in range(len(v)):
            sum += v[i]*v1[i]
        return sum
        
        
class CSDocumentVector(object):
    def __init__(self, params, query):
        self.tf = {}
        self.query = query
        for term in query.split():
            self.tf[term] = 0
        self.tf_computer = p.tf_computer
        self.term_matcher = p.term_matcher
        self.bsmooth = p.bsmooth
    def add_term(self, term):
        if self.term_matcher(term, self.tf):
            self.tf[term] += 1
    def value(self, body_length):
        return [self.tf_computer(self.tf[term])/float(body_length + self.bsmooth) for term in self.query.split()]
        
        
class CSQueryVector(object, tf_computer):
    def __init__(self, query):
        self.N, self.df_hash = idf_gen.read_idf_file('./')
        self.raw = {}
        for term in query.split():
            if term in self.raw:
                self.raw[term] += 1
            else:
                self.raw[term] = 1
                if not term in self.df_hash:
                    self.df_hash = math.log10(self.N) - math.log10(1.1)
    def value(self):
        return [self.tf_computer(self.raw[term])*self.df_hash[term] for term in self.query.split()]
        
        
class VectorParameters(object):
    def __init__(self, up, tp, bp, hp, ap, bsmooth):
        self.up = up
        self.tp = tp
        self.bp = bp
        self.hp = hp
        self.ap = ap
        self.bsmooth = bsmooth        
    def linear_tf(count):
        return count
    def log10_tf(count):
        return 1 + math.log10(count)
    def stemming_term_match(term, term_hash):
        raise "Unsupported"
    def equality_term_match(term, term_hash):
        if term in term_hash:
            return True
        else:
            return False
            
            
#inparams
#  featureFile: file containing query and url features
def main(featureFile):
    #output file name
    outputFile = "ranked.txt" #Please don't change this!
    params = VectorParameters(1, 1, 1, 1, 1, 111)
    builder = CSRankingBuilder(params)
    (queries, features) = builder.extractFeatures(featureFile)
    scored = {}
    heapq.heappop(scores)

    for query in queries.itemiter():
        query.compute_score()
    print "QUERIES = ", queries
    print "FEATURES ############################################################### ", features
    
    #calling baseline ranking system, replace with yours
    rankedQueries = cosine_similarity(queries, features)
    
    #print ranked results to file
    printRankedResults(rankedQueries)
   
   
   #inparams
#  queries: map containing list of results for each query
#  features: map containing features for each query,url pair
#return value
#  rankedQueries: map containing ranked results for each query
def cosine_similarity(queries, features):
    rankedQueries = {}
    for query in queries.keys():
      results = queries[query]
      #features[query][x].setdefault('body_hits', {}).values() returns the list of body_hits for all query terms
      #present in the document, empty if nothing is there. We sum over the length of the body_hits array for all
      #query terms and sort results in decreasing order of this number
      rankedQueries[query] = sorted(results, 
                                    key = lambda x: sum([len(i) for i in 
                                    features[query][x].setdefault('body_hits', {}).values()]), reverse = True)

    return rankedQueries


#inparams
#  queries: contains ranked list of results for each query
#  outputFile: output file name
def printRankedResults(queries):
    for query in queries:
      print("query: " + query)
      for res in queries[query]:
        print("  url: " + res)

       
if __name__=='__main__':
    if (len(sys.argv) < 2):
      print "Insufficient number of arguments" 
    main(sys.argv[1])
